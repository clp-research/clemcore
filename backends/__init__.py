import abc
import importlib
import inspect
import json
import os
import nltk
import logging
import logging.config
from abc import ABC
from types import SimpleNamespace

from typing import Dict, List, Tuple, Any, Type, Union

import yaml

project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# Configure logging
with open(os.path.join(project_root, "logging.yaml")) as f:
    conf = yaml.safe_load(f)
    log_fn = conf["handlers"]["file_handler"]["filename"]
    log_fn = os.path.join(project_root, log_fn)
    conf["handlers"]["file_handler"]["filename"] = log_fn
    logging.config.dictConfig(conf)


def get_logger(name):
    return logging.getLogger(name)


# Load backend dynamically from "backends" sibling directory
# Note: The backends might use get_logger (circular import)
def load_credentials(backend, file_name="key.json") -> Dict:
    key_file = os.path.join(project_root, file_name)
    with open(key_file) as f:
        creds = json.load(f)
    assert backend in creds, f"No '{backend}' in {file_name}. See README."
    assert "api_key" in creds[backend], f"No 'api_key' in {file_name}. See README."
    return creds


class ModelSpec(SimpleNamespace):
    PROGRAMMATIC_SPECS = ["mock", "dry_run", "programmatic", "custom", "_slurk_response"]
    HUMAN_SPECS = ["human", "terminal"]

    def __init__(self, **kwargs):
        super().__init__(**kwargs)

    def unify(self, other: "ModelSpec") -> "ModelSpec":
        """ Return whether the other ModelSpec is fully contained within this ModelSpec """
        result = nltk.featstruct.unify(self.__dict__, other.__dict__)
        if result is None:
            raise ValueError(f"{self} does not unify with {other}")
        return ModelSpec(**result)

    def has_temperature(self):
        return hasattr(self, "temperature")

    def has_backend(self):
        return hasattr(self, "backend")

    @classmethod
    def from_name(cls, model_name: str):
        if model_name is None:
            raise ValueError(f"Cannot create ModelSpec because model_name is None (but required)")
        return cls(model_name=model_name)

    @classmethod
    def from_dict(cls, spec: Dict):
        return cls(**spec)

    def is_programmatic(self):
        return self.model_name in ModelSpec.PROGRAMMATIC_SPECS

    def is_human(self):
        return self.model_name in ModelSpec.HUMAN_SPECS


class Model(abc.ABC):

    def __init__(self, model_spec: ModelSpec):
        self.model_spec = model_spec
        assert hasattr(model_spec, "model_name"), "The passed ModelSpec must have a model_name attributed"

    def get_name(self) -> str:
        return self.model_spec.model_name

    @abc.abstractmethod
    def get_temperature(self) -> float:
        # note: we need this for now to create the results folder
        pass

    @abc.abstractmethod
    def generate_response(self, messages: List[Dict]) -> Tuple[Any, Any, str]:
        """Put prompt in model-specific format and get its response.

        Args:
            messages (List[Dict]): The dialogue context represented as a list
                of turns. Entry element is a dictionary containing one key
                "role", whose value is either "user" or "assistant", and one
                key "content", whose value is the message as a string.
            model (str): the name of the model

        Returns:
            Tuple[Any, Any, str]: The first element is the prompt object as
            passed to the LLM (i.e. after any model-specific manipulation).
            Return the full prompt object, not only the message string.

            The second element is the response object as gotten from the model,
            before any manipulation. Return the full prompt object, not only
            the message string.

            These must be returned just to be logged by the GM for later inspection.

            The third element is the response text, i.e. only the actual message
            generated by the model as a string (after any needed manipulation,
            like .strip() or excluding the input prompt).
        """
        pass


class Backend(Model, ABC):
    """ Marker class for a model provider. For now the Backend itself acts as if it would be the Model."""

    def __init__(self, model_spec: ModelSpec):
        super().__init__(model_spec)
        self.temperature = model_spec.temperature if model_spec.has_temperature() else 0.0

    def get_temperature(self) -> float:
        return self.temperature

    def __repr__(self):
        return str(self)

    def __str__(self):
        return f"{self.__class__.__name__}({self.model_spec.model_name})"


class MockModel(Backend):

    def __init__(self, model_spec=ModelSpec(model_name="programmatic")):
        super().__init__(model_spec)

    def generate_response(self, messages: List[Dict]) -> Tuple[Any, Any, str]:
        raise NotImplementedError("This should never be called but is handled in Player")


class HumanModel(Backend):

    def __init__(self, model_spec=ModelSpec(model_name="human")):
        super().__init__(model_spec)

    def generate_response(self, messages: List[Dict]) -> Tuple[Any, Any, str]:
        raise NotImplementedError("This should never be called but is handled in Player")


def is_backend(obj):
    if inspect.isclass(obj) and issubclass(obj, Backend):
        return True
    return False


_backend_registry: Dict[str, Type] = dict()  # we store references to the class constructor
_model_registry: List[ModelSpec] = list()  # we store model specs so that users might use model_name for lookup


def load_model_registry(_model_registry_path: str = None):
    if not _model_registry_path:
        _model_registry_path = os.path.join(project_root, "backends", "model_registry.json")
    if not os.path.isfile(_model_registry_path):
        raise FileNotFoundError(f"The file model registry at '{_model_registry_path}' does not exist. "
                                f"Create model registry as a model_registry.json file and try again.")
    with open(_model_registry_path) as f:
        _model_listing = json.load(f)
        for _model_entry in _model_listing:
            _model_spec: ModelSpec = ModelSpec.from_dict(_model_entry)
            if not _model_spec.has_backend():
                raise ValueError(
                    f"Missing backend definition in model registry for model_name='{_model_spec.model_name}'. "
                    f"Check or update the backends/model_registry.json and try again."
                    f"A minimal entry is {{'model_name':<name>,'backend':<backend>}}.")
            _model_registry.append(_model_spec)


def _register_backend(backend_name: str):
    """
    Dynamically loads the Backend in the file with name <backend_name>_api.py into the _backend_registry.
    Raises an exception if no such file exists or the Backend class could not be found.

    :param backen_name: the prefix of the <backend_name>_api.py file
    """
    backends_root = os.path.join(project_root, "backends")
    backend_module = f"{backend_name}_api"
    backend_path = os.path.join(backends_root, f"{backend_module}.py")
    if not os.path.isfile(backend_path):
        raise FileNotFoundError(f"The file '{backend_path}' does not exist. "
                                f"Create such a backend file or check the backend_name '{backend_name}'.")
    module = importlib.import_module(f"backends.{backend_module}")
    backend_subclasses = inspect.getmembers(module, predicate=is_backend)
    if len(backend_subclasses) == 0:
        raise LookupError(f"There is no Backend defined in {backend_module}. "
                          f"Create such a class and try again or check the backend_name '{backend_name}'.")
    if len(backend_subclasses) > 1:
        raise LookupError(f"There is more than one Backend defined in {backend_module}.")
    _, backend_cls = backend_subclasses[0]
    _backend_registry[backend_name] = backend_cls
    return backend_cls


def _load_model_for(model_spec: ModelSpec) -> Model:
    backend_name = model_spec.backend
    if backend_name not in _backend_registry:
        _register_backend(backend_name)
    backend_cls = _backend_registry[backend_name]
    return backend_cls(model_spec)


def get_model_for(model_spec: Union[str, Dict, ModelSpec]) -> Model:
    """
    :param model_spec: the model spec for which a supporting backend has to be found
    :return: the backend registered that supports the model
    """
    if isinstance(model_spec, str):
        model_spec = ModelSpec.from_name(model_spec)
    if isinstance(model_spec, dict):
        model_spec = ModelSpec.from_dict(model_spec)

    if model_spec.is_human():
        return HumanModel(model_spec)
    if model_spec.is_programmatic():
        return MockModel(model_spec)

    for registered_spec in _model_registry:
        try:
            model_spec = model_spec.unify(registered_spec)
        except ValueError:
            continue

    if not model_spec.has_backend():
        raise ValueError(f"Model spec requires backend after unification, but there might be no entry in model registry "
                         f"for model_name='{model_spec.model_name}'. "
                         f"Check or update the backends/model_registry.json or pass the backend directly and try again. "
                         f"A minimal entry is {{'model_name':<name>,'backend':<backend>}}.")
    model = _load_model_for(model_spec)
    return model
