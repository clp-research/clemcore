{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a662378a74a57d91",
   "metadata": {},
   "source": [
    "# Making a new clemgame\n",
    "*While written for prior versions of `clemcore`, reading the documentation on [how to add new games](howto_add_games.md) and how to [log events and build records](logging_and_scoring.md) is recommended, but not necessary.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443993a208f339b5",
   "metadata": {},
   "source": [
    "## Index\n",
    "[Game concept](#game-concept)\n",
    "\n",
    "[Clemgame components](#clemgame-components)\n",
    "\n",
    "[Clemgame template and workspace setup](#clemgame-template-and-workspace-setup)\n",
    "\n",
    "[Instances and resources basics](#instances-basics-and-game-resources)\n",
    "\n",
    "[Player implementation](#player-implementation)\n",
    "\n",
    "[GameMaster implementation](#gamemaster-implementation)\n",
    "\n",
    "[GameBenchmark implementation](#gamebenchmark-implementation)\n",
    "\n",
    "[Testing and refinement](#testing-and-refinement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552469143939fea9",
   "metadata": {},
   "source": [
    "The core parts of a clemgame are separated into classes:\n",
    "- **Player** class handles players of the game, holding their message history and making calls to a backend model to generate responses.\n",
    "- **GameMaster** class handles the game loop, determining what each player gets prompted with when\n",
    "- **GameScorer** class handles scoring based on episode records\n",
    "- **GameBenchMark** class coordinates benchmark runs of the clemgame, initializing GameMaster with game instances and GameScorer with recorded episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618c0b497c287bfd",
   "metadata": {},
   "source": [
    "# Game concept\n",
    "The first step of creating a new clemgame is to come up with a game concept, or to find an existing dialogue game to adapt. In either case, it is important that the rules of the game can be implemented programmatically. While you can implement a clemgame with complex parsing, it is recommended to keep rules simple enough to understand benchmark results without learning code intricacies of the clemgame implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8d8e04b80da44",
   "metadata": {},
   "source": [
    "## Example game concept\n",
    "Let's implement a simple two-player game we will call `firstlast`.\n",
    "\n",
    "The players should engage in a back-and-forth conversation about a predefined topic. Player A starts with an utterance whose first and last word must start with a predefined letter, say  `d`. Player B must then reply with an utterance whose first and last word must be the next one in the alphabet (here, an `e`). And so on, for `n` rounds (where each round comprises a single turn, with an utterance from A or B). If an utterance does not conform to these rules (i.e. it is incorrect), the players lose the game. We also define a move format rule: If an utterance does not start with `I SAY: ` (i.e., it is invalid), the game is immediately aborted. If all utterances up to turn `n` are valid and correct, the game is successful.\n",
    "\n",
    "For instance, if the topic is `birds`, the initial letter is `h` and the number of ~~turns~~ rounds is 2, this would be a successful game:\n",
    "\n",
    "- Player A: \"Hi! I love birds, but it's hard to identify them. I need help.\" (h: hi / help)\n",
    "- Player B: \"I know what you mean. I can try to help, please describe it.\" (i: I/ it)\n",
    "- Player A: \"Just a moment... Ok, it's blue but looks like an Eurasian jay.\" (j: just / jay)\n",
    "- Player B: \"Kick in more details, otherwise I don't know.\" (k: kick / know)\n",
    "\n",
    "In each round, we need to check two aspects:\n",
    "- Does the utterance have a valid form fit to be parsed? Failing to meet this leads to the game being aborted. (Move format rule.)\n",
    "- Does the utterance fulfil the game rules for a successful round? Failing to meet this leads to game being lost. (Game rules.)\n",
    "\n",
    "To make things simple, in this example we will check only these conditions:\n",
    "- Validity: Does the utterance start with `I SAY:`?\n",
    "- Correctness: Do the first and last words begin with the same, correct letter at play?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a4d58dbab06d9c",
   "metadata": {},
   "source": [
    "# Clemgame components\n",
    "A clemgame needs at least the following components:\n",
    "\n",
    "1. [Game resources](#instances-basics-and-game-resources): All data, prompt templates and other files that are necessary to create instances of a game and to group these instances into experiments.\n",
    "2. [Instances](#instances-basics-and-game-resources): A JSON file containing the configuration of each instance of this game, grouped into experiments. This must be done by a script named `instancegenerator.py`, with a class that inherits from `GameInstanceGenerator`.\n",
    "3. [Players](#player-basics): A script that defines the programmatic behaviour and any other attributes of a player, inheriting from the `Player` base class. (This can be implemented in a file named `players.py`.)\n",
    "4. [Game Master](#gamemaster-implementation): A script that controls and enforces the defined move and game rules and dynamics, inheriting from the `GameMaster` base class. This must be implemented in the `master.py` file.\n",
    "5. [Game Benchmark](#gamebenchmark-implementation): A class that realises the game's running behavior for benchmarking, inheriting from `GameBenchmark`. This can also live in the file `master.py`.\n",
    "6. [Game registry](#game-registry) entry: A JSON-format specification of the clemgame required by the `clemcore` framework to locate the clemgame's files.\n",
    "\n",
    "Let's walk through the implementation step by step. We'll write the contents of `instancegenerator.py`, `master.py` and `players.py`, that you should save as files to run the game.\n",
    "\n",
    "**Note**: For the mandatory methods, always check the parent class documentation to be sure about the required and optional arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb366c500f2791f",
   "metadata": {},
   "source": [
    "# Clemgame template and workspace setup\n",
    "The most convenient way to create a clemgame is to start with the template repository. It contains a minimal clemgame implementation as a base to work from, found in the `empty_template` directory.\n",
    "\n",
    "To start, follow these steps:\n",
    "1. Clone the clemgame template repository from https://github.com/clembench/clemgame-template . The directory you clone it to will be the workspace directory.\n",
    "2. Set up a python virtual environment with `clemcore`, as described in the [template readme](https://github.com/clembench/clemgame-template/blob/main/README.md).\n",
    "3. Inspect the template's files and structure.\n",
    "4. Create a directory for your clemgame: Copy the `empty_template` directory and rename it. For the example clemgame below, name it `firstlast`.\n",
    "\n",
    "The example implementation below is based on this template."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf1cd13cfa40d1b",
   "metadata": {},
   "source": [
    "# Instances basics and game resources\n",
    "Instances of the `taboo` clemgame are located under `clembench/taboo/in` in the `instances.json` file. All clemgames must follow this directory structure, with the clemgame's base directory containing a subdirectory named `in` which contains the `instances.json` file.\n",
    "\n",
    "The `instances.json` file contains a JSON object with the single key `experiments`, which holds a list of JSON objects, each corresponding to an experiment. An experiment holds clemgame parameters that apply for all its instances, and is used to evaluate and compare scores between different variants of a clemgame. The keys `name`, to identify different experiments, and `game_instances` are mandatory for all experiment objects.\n",
    "\n",
    "An experiment object's `game_instances` key holds a list of the experiment's instances, each containing different data that is needed by the Game Master (explained below) to play an individual episode of the clemgame.\n",
    "## Game resources\n",
    "Resources - located in the `resources` subdirectory - are files that are accessed for instance generation or by the Game Master running the clemgame.\n",
    "\n",
    "Conventionally, initial prompts that explain the game and its rules, and contain the starting state for an episode, are stored as `.template` files in `resources/initial_prompts`. Clemcore provides convenient methods to load these `.template` files (see below).\n",
    "\n",
    "As you can see in the `taboo` files, initial prompt templates usually contain placeholder strings like `$TARGET_WORD$` that are replaced with instance values to create individual initial prompts for each instance.\n",
    "\n",
    "## Example clemgame instances and resources\n",
    "(In this example, defining an episode requires instantiating the initial prompts and 3 additional parameters: The topic, the letter for the first player and the number of turns for that game play.)\n",
    "\n",
    "In this example, an instance defines which initial prompts to use and 3 additional parameters: The topic, the letter for the first player and the number of rounds that need to be successfully played.\n",
    "\n",
    "### Defining prompts with game rules\n",
    "\n",
    "The players need to be instructed on what the rules of the game are, possibly with some examples, at the beginning of the game. For that, we must define the initial prompts passed to player A and player B.\n",
    "\n",
    "In the template text, we can define variables that will later be filled with our chosen values (here: topic, first letter, number of rounds). The prompts need to be adjusted for player A and B according to their roles. For example:\n",
    "\n",
    "Player A:\n",
    "```\"Let's play a game. You must have a conversation about $topic with your partner. Your first turn must start and end with words that begin with the letter $letter. The reply of your partner must be similar, with the letter that comes after $letter in the alphabet. Then it's your turn again with the next letter, and so on. You'll do it for $n_turns turns. Always start your utterance with I SAY: and then give your answer. If you break the rules, you lose.\"```\n",
    "\n",
    "Player B:\n",
    "```\"Let's play a game. You must have a conversation about $topic with your partner. Their first turn must start and end with words that begin with the letter $letter. Your reply must be similar, with the letter that comes after $letter in the alphabet. Then it's their turn again with the next letter, and so on. You'll do it for $n_turns turns. Always start your utterance with I SAY: and then give your answer. If you break the rules, you lose.\"```\n",
    "NOTE: These templates are assuming the use of `string.Template` to fill the placeholders (starting with `$`, like `$n_turns`).\n",
    "\n",
    "You can later refine these initial prompts based on how models handle them. Save the initial prompts as plain texts using `.template` as an extension in the `initial_prompts` directory. You can save many templates if you wish to test different prompts, and read each of them when you generate game instances (see below). Note that this template is just an example and has not been tested. (Decide what amount of prompt engineering you will do at this step. Once you are satisfied with your preliminary results (i.e. the model can process the instructions well enough for your purposes), save to file...)\n",
    "\n",
    "### Additional resources\n",
    "Everything else needed to create instances for the game or to be accessed by the game master should be saved into the `firstlast/resources` directory as well.\n",
    "\n",
    "Let's create a `topics.txt` file with a list of topics that we can later sample from to create our instances. The following cell will do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c76137fd40a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['dogs', 'cats', 'birds', 'trees']\n",
    "\n",
    "with open('resources/topics.txt', 'w') as file:\n",
    "    for topic in topics:\n",
    "        file.write(topic + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6758cac3014cc63",
   "metadata": {},
   "source": [
    "You can also write the topics manually using any text editor or IDE. Intended `topics.txt` content:\n",
    "```\n",
    "dogs\n",
    "cats\n",
    "birds\n",
    "trees\n",
    "```\n",
    "### Creating game instances\n",
    "Create a Python script called `instancegenerator.py` in `firstlast/`. Running this file will create a `JSON` file in `firstlast/in/`, called `instances.json`. The clemcore framework provides base classes to organise this. All we need to do is write a class that inherits from the `GameInstanceGenerator` class and write its `on_generate` method according to our needs. Then, in the main call, instantiate this class and call its `.generate()` method.\n",
    "\n",
    "In the `on_generate` method, we define experiments and then define instances of each experiment. An instance is a configuration of one specific game play and an experiment is a set of related instances. We can define what is an experiment and what is an instance depending on what dimensions we want to evaluate later.\n",
    "\n",
    "For our game, let's define an experiment as a set of instances about the same topic. To define an instance in an experiment, we define the initial letter, the initial prompts and the number of turns. This is useful if we wish to evaluate the performance of LLMs on variations of the same topic. Another possibility would be to define experiment as a set of instances with the same number of turns, and then each instance could be about different topics. That's our choice.\n",
    "\n",
    "Running this will automatically create a `JSON` file with a key `experiments`, which is a list of experiments. Each element has a name and a list of `game_instances`. A game instance should have at least a `game_id` assigning an index to that instance and other keys and values that are necessary to play the game. Here, the initial prompts can have their slots already filled with the instance's values (or we can leave that for the `setup` method of the game master).\n",
    "\n",
    "Here is an example of the structure we need:\n",
    "\n",
    "```JSON\n",
    "{\n",
    "    \"experiments\": [\n",
    "        {\n",
    "            \"name\": \"NAME_1\",\n",
    "            \"game_instances\": [\n",
    "                {\n",
    "                    \"game_id\": 0,\n",
    "                    \"first_letter\": \"LETTER\",\n",
    "                    \"n_turns\": \"N\",\n",
    "                    \"prompt_player_a\": \"PROMPT_A\",\n",
    "                    \"prompt_player_b\": \"PROMPT_B\",\n",
    "                },\n",
    "                {\n",
    "                    \"game_id\": 1,\n",
    "                    \"first_letter\": \"LETTER\",\n",
    "                    \"n_turns\": \"N\",\n",
    "                    \"prompt_player_a\": \"PROMPT_A\",\n",
    "                    \"prompt_player_b\": \"PROMPT_B\",\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"NAME_2\",\n",
    "            \"game_instances\": [\n",
    "                {\n",
    "                    \"game_id\": 0,\n",
    "                    \"first_letter\": \"LETTER\",\n",
    "                    \"n_turns\": \"N\",\n",
    "                    \"prompt_player_a\": \"PROMPT_A\",\n",
    "                    \"prompt_player_b\": \"PROMPT_B\",\n",
    "                },\n",
    "                {\n",
    "                    \"game_id\": 1,\n",
    "                    \"first_letter\": \"LETTER\",\n",
    "                    \"n_turns\": \"N\",\n",
    "                    \"prompt_player_a\": \"PROMPT_A\",\n",
    "                    \"prompt_player_b\": \"PROMPT_B\",\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "***Note***: The `instances.json` file should contain everything that the game master needs to set up the configuration to play the game! We can add as many keys and values and we need.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815b1bd2dc3e40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the contents of this cell as games/firstlast/instancegenerator.py\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import logging\n",
    "\n",
    "from clemcore.clemgame import GameInstanceGenerator\n",
    "\n",
    "# initialize logging:\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# set the name of the game in the script, as you named the directory\n",
    "# this name will be used everywhere, including in the table of results\n",
    "GAME_NAME = 'firstlast'\n",
    "# we will create 10 instances for each experiment; vary this as you wish\n",
    "N_INSTANCES = 10\n",
    "# if the generation involves randomness, remember to set a random seed\n",
    "SEED = 123\n",
    "\n",
    "class FirstLastGameInstanceGenerator(GameInstanceGenerator):\n",
    "    def __init__(self):\n",
    "        # always do this to initialise GameInstanceGenerator\n",
    "        super().__init__(os.path.dirname(__file__))\n",
    "\n",
    "    # define on_generate, a mandatory method\n",
    "    def on_generate(self):\n",
    "        # get the list of topics, which will be our experiments\n",
    "        topics = self.load_file('resources/topics.txt').strip('\\n').split('\\n')\n",
    "        # get the prompts for player a and player b\n",
    "        # we'll keep the prompts fixed in all instances, replacing only the\n",
    "        # necessary slots (but you can do it differently)\n",
    "        prompt_a = self.load_template('resources/initial_prompts/initial_prompt_a')\n",
    "        prompt_b = self.load_template('resources/initial_prompts/initial_prompt_b')\n",
    "\n",
    "        # building the file, one experiment at a time\n",
    "        for topic in topics:\n",
    "            # create an experiment (for us, named after a topic)\n",
    "            experiment = self.add_experiment(topic)\n",
    "            # build N_INSTANCES instances for each experiment\n",
    "            for game_id in range(N_INSTANCES):\n",
    "                # set the parameters\n",
    "                # here we do it randomly, but that can also be read from a file\n",
    "                # one of the first 5 letters in the alphabet\n",
    "                letter = random.choice(string.ascii_lowercase[:5])\n",
    "                # up to 8 turns, so that we don't run out of letters\n",
    "                n_turns = random.randint(3, 8)\n",
    "                # create a game instance, using a game_id counter/index\n",
    "                instance = self.add_game_instance(experiment, game_id)\n",
    "                # populate the game instance with its parameters\n",
    "                instance['first_letter'] = letter\n",
    "                instance['n_turns'] = n_turns\n",
    "                instance['prompt_player_a'] = self.create_prompt(\n",
    "                    topic, prompt_a, letter, n_turns)\n",
    "                instance['prompt_player_b'] = self.create_prompt(\n",
    "                    topic, prompt_b, letter, n_turns)\n",
    "\n",
    "    # an additional method, specific for our example\n",
    "    def create_prompt(self,\n",
    "                      topic: str,\n",
    "                      prompt: str,\n",
    "                      letter: str,\n",
    "                      n_turns: int) -> str:\n",
    "        \"\"\"Replace a prompt template with slot values.\"\"\"\n",
    "        text = string.Template(prompt).substitute(topic=topic, letter=letter,\n",
    "                                                  n_turns=n_turns)\n",
    "        return text\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    random.seed(SEED)\n",
    "    # always call this, which will actually generate and save the JSON file\n",
    "    FirstLastGameInstanceGenerator().generate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d1f9cf8bc3a9cd",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "- Write a class that inherits from ```GameInstanceGenerator```.\n",
    "- You must implement the ```on_generate``` method, which should call ```self.add_experiment()``` to add experiments and ```self.add_game_instance()``` to add instances. Populate the game instance with keys and values.\n",
    "- ```GameInstanceGenerator``` has methods to load various files inside the game directory, for example ```self.load_template()``` and  ```self.load_file()```.\n",
    "- In ```'__main__'```, call ```FirstLastGameInstanceGenerator().generate()```.\n",
    "- Set a random seed if your generation relies on randomness; when you need new instances, change the random seed.\n",
    "\n",
    "An ideal clemgame instance generation allows creating varied new sets of instances by simply running `instancegenerator.py` with a new seed value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabca2044e7f5b18",
   "metadata": {},
   "source": [
    "# Player implementation\n",
    "Players are handled by child classes of the clemcore `Player` class, which holds the message history of a player and communicates with the model backend. A programmatic response method for testing is also commonly set up according to the clemgame.\n",
    "## Defining the Player class\n",
    "Create a python file called `player.py` in the workspace directory. (If your player class/es are very compact, you might define them in `master.py` instead, the creation of which is covered [below](#gamemaster-implementation). The 'empty' template has a minimal player definition in its `master.py` which you can extend for this purpose.)\n",
    "\n",
    "In our game, the role of player A and B are symmetric, i.e. they behave the same way and have the same tasks and goals. So we can define one class and instantiate both players from it. If in your game players have different roles, then define two types of Player objects. The only method that we must implement is `_custom_response()`, which must define a programmatic behaviour for this player. The rest (getting and generating utterances via API calls to LLMs) is taken care of by the framework (we'll see below how to use it). Of course, you can add more methods that relate to the behaviour of the player in your game.\n",
    "\n",
    "The programatic behaviour is useful in two cases: when the player is really a program (i.e. it sends only predefined messages, e.g. read from a file, not retrieved from an LLM agent) or for testing your program, using the `mock` setting that does not make API calls to any LLMs. For the first case, the argument `model_name` in the initialisation should be set to `\"programmatic\"`.\n",
    "\n",
    "We also initialise a list to represent the dialogue history of this player. It will be incrementally built during the game play by appending new utterances to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a6016486e280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the contents of this cell as firstlast/players.py\n",
    "\n",
    "import random\n",
    "import logging\n",
    "from string import ascii_lowercase as letters\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "from clemcore.clemgame import Player\n",
    "from clemcore.backends import Model\n",
    "\n",
    "# initialize logging:\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Speaker(Player):\n",
    "    def __init__(self, model: Model, letter: str, firstlast_player: str, name: str = None):\n",
    "        # if the player is a program and you don't want to make API calls to\n",
    "        # LLMS, use model='{\"model_name\": programmatic\"}'\n",
    "        super().__init__(model, name)\n",
    "        self.player: str = firstlast_player\n",
    "        self.initial_letter: str = letter\n",
    "\n",
    "    # implement this method as you prefer, with these same arguments\n",
    "    def _custom_response(self, context: Dict) -> str:\n",
    "        \"\"\"Return a mock message with the suitable letter and format.\n",
    "        Args:\n",
    "            context: The dialogue context to which the player should respond. Base class method, not used in this example.\n",
    "        Returns:\n",
    "            Mock message with the suitable letter and format.\n",
    "        \"\"\"\n",
    "        # get the first letter of the content of the last message\n",
    "        # messages is a list of dictionaries with messages in openai API format\n",
    "        turn_idx = len(self._messages)  # will be 1 if only initial prompt message is in message history\n",
    "\n",
    "        if turn_idx == 1 and self.player == 'A':\n",
    "            letter = 'I SAY: ' + self.initial_letter\n",
    "        else:\n",
    "            previous_letter = self._messages[-1]['content'][7].lower()\n",
    "            # introduce a small probability that the player fails\n",
    "            letter = self._sample_letter(previous_letter)\n",
    "        # return a string whose first and last tokens start with the next letter\n",
    "        return f\"{letter}xxx from {self.player}, turn {turn_idx} {letter.replace('I SAY: ', '')}xxx.\"\n",
    "\n",
    "    # an additional method specific for this game\n",
    "    # for testing, we want the utterances to be invalid or incorrect sometimes\n",
    "    def _sample_letter(self, letter: str) -> str:\n",
    "        \"\"\"Randomly decide which letter to use in a custom response message.\"\"\"\n",
    "        prob = random.random()\n",
    "        index = letters.index(letter)\n",
    "        if prob < 0.05:\n",
    "            # correct but invalid (no tag)\n",
    "            return letters[index + 1]\n",
    "        if prob < 0.1:\n",
    "            # valid tag but wrong letter\n",
    "            return 'I SAY: ' + letter\n",
    "        # valid and correct\n",
    "        return 'I SAY: ' + letters[index + 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557b2d1b989a847f",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "- Write a class that inherits from `Player`.\n",
    "- Define its `_custom_response()` method, which implements the programmatic behaviour of the player (for testing, or because it is really a program) and returns a string.\n",
    "- A `ModelSpec` defines the model to use, and the programmatic custom response is used by passing `model='{\"model_name\": programmatic\"}'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572117b4302ae731",
   "metadata": {},
   "source": [
    "# GameMaster implementation\n",
    "The core clemgame functionality is implemented in its game master class, containing the play loop and handling any game-specific interaction. While a game master can be fully custom and based on just the minimal implementation in the clemcore `GameMaster` base class, the more extensive `DialogueGameMaster` base class inheriting from `GameMAster` is commonly used. `DialogueGameMaster` implements the game conversation loop described in the clembench papers, and only requires extension for game-specific behavior. The game master must be implemented in `master.py`, located in the root directory of a clemgame.\n",
    "## Defining the GameMaster class\n",
    "Open `master.py` in the `firstlast` directory. Remove the `class SomeGamePlayer(Player)` definition (for your own clemgame, you can rename this class and add it to it if your player class does not need much extra code).\n",
    "\n",
    "We need define the game master, a class that inherits from `DialogueGameMaster` and implement certain required methods, mainly its `_on_setup()` method and play loop methods like `_does_game_proceed()`.\n",
    "\n",
    "The metrics that every game must compute are listed at `clemcore/clemgame/metrics.py`, described in [log events and build records](logging_and_scoring.md) and in more detail in the paper's appendix. Note: You should **not** implement `METRIC_PLAYED` if you use the provided evaluation scripts, because this metric is inferred from `METRIC_ABORTED` there. Besides, any number of additional game-specific metrics can also be logged (see more below).\n",
    "\n",
    "These are the mandatory methods. However, for readability, we will also write auxiliary methods.\n",
    "\n",
    "**IMPORTANT**: The game master has to log ***every event*** that is relevant to reconstruct the interaction, build the transcript and evaluate the game.\n",
    "\n",
    "The `DialogueGameMaster` is also a `GameResourceLocator`, which has special methods to access and write files in the game's local directory, and a `GameRecorder`, which knows how to log events. We'll see below how to use it.\n",
    "\n",
    "The `GameMaster` and `DialogueGameMaster` base classes have a `GameResourceLocator` to access resources and a `GameRecorder` to be used by all involved class objects.\n",
    "### Initialisation\n",
    "\n",
    "The first step is to initialise the game master. The `__init__` method gets the experiment object and a list of `Model` objects (`Model` objects are given by the benchmark scripts and handled by clemcore backends).\n",
    "\n",
    "Rename the `DialogueGameMaster` child class in `master.py` to `FirstLast`.\n",
    "\n",
    "Change the docstring of the class to fit the game: `\"\"\"Implement mechanisms for playing FirstLast.\"\"\"`.\n",
    "\n",
    "The beginning of `master.py` should now look like this:\n",
    "```python\n",
    "import os.path\n",
    "from typing import Dict, Tuple, List, Union\n",
    "from string import ascii_lowercase as letters\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import clemcore.metrics as ms\n",
    "from clemcore.clemgame import GameSpec, GameMaster, GameBenchmark, Player, DialogueGameMaster, GameScorer, \\\n",
    "    GameError, ParseError, RuleViolationError\n",
    "from clemcore.backends import Model\n",
    "\n",
    "# import the Speaker player class:\n",
    "from player import Speaker\n",
    "\n",
    "# initialize logging:\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class FirstLast(DialogueGameMaster):\n",
    "    \"\"\"Implement mechanisms for playing FirstLast.\"\"\"\n",
    "    def __init__(self, game_name: str, game_path: str, experiment: Dict, player_models: List[Model]):\n",
    "        super().__init__(game_name, game_path, experiment, player_models)\n",
    "\n",
    "````\n",
    "\n",
    "### Keeping records\n",
    "`DialogueGameMaster` handles all default record keeping, but game-specific records need to be implemented using the `log_key()` method.\n",
    "\n",
    "Note: see details about keeping records in [log events and build records](logging_and_scoring.md).\n",
    "#### Default record keeping\n",
    "All events that occur during the game, i.e. all actions by the game master and by the players, must be documented. This is done by the methods of `GameRecorder` of the `GameMaster`. The essential ones are:\n",
    "\n",
    "- At the beginning of every turn, call `log_next_turn()` (a turn is one player response and its processing by the game master). This is already implemented in the `DialogueGameMaster` base class play loop.\n",
    "- In the game setup, call `log_players()` in order to log the models that are playing this episode of the game. This is already implemented in the `DialogueGameMaster` base class setup.\n",
    "- Use `log_event()` to log all types of actions with a `to` and `from_`.\n",
    "- The `action` object passed to `log_event()` must contain at least a key `type` and a key `content`. The first can be `send message`, `get message`, `metadata`, `parse`, `error`, `invalid format` or any game-specific types. Content is the actual message to de displayed in the transcript.\n",
    "- Use only the values 'Player 1', 'Player 2' or 'GM' for the `from_` and `to` arguments. Messages that the game master emits to itself should have 'GM' both in `from_` and `to`.\n",
    "- All events that involve making an API call should pass an additional `call` argument to `log_event()` containing the actual and exact API input and output objects, for posterior inspection if necessary. The `Player` base class already implements this.\n",
    "- Any other episode-level object needed for scoring or documentation can be logged with `log_key()`.\n",
    "#### Record files\n",
    "Every action that is logged gets saved into the episode's `interactions.json` file after it is played. This file is then used to build game transcripts and to compute evaluation scores. The episode's `requests.json` file contains the API calls, saved when `log_event()` is called with a `call` argument. If you use a list, make deep copies to guarantee that you are not logging an object that mutates.\n",
    "#### Records and scoring\n",
    "The `GameScorer`'s (see [here](#gamescorer-implementation)) `compute_scores()` method gets the `interactions.json` dictionary as argument, so every key and value that is necessary to compute scores should be logged into the interaction file.\n",
    "### IMPORTANT: Inspecting the game records\n",
    "During development, always check the generated `interactions.json` and `requests.json` to make sure that the API calls are passing the correct structure and that the records are being correctly saved.\n",
    "\n",
    "`interactions.json` is built by the game master as a way to represent the actual interaction (with all its meta-events like parsing messages or checking game rules). This is used to create the transcripts, which are a user-friendly visualisation of the interaction. But remember that this does not reflect the actual API calls, this only reflects what the game master makes of the game!\n",
    "\n",
    "[Testing and refinement](#testing-and-refinement) has an example of checking `interactions.json` records.\n",
    "\n",
    "The actual prompts and responses from the model are saved into `requests.json`, when an action is logged with its corresponding prompt and response object (see below how to do it). This file will reflect what was actually passed to and from the LLM. Remember that LLMs do not keep a internal state, so every call to a model must contain its full dialogue history. Also remember that when there are two LLMs playing at once, each will have its own dialogue history, which may be different! That's why, for debugging purposes, only looking at `interactions.json` is not enough, because it may not reflect exactly what the LLMs consumed and output.\n",
    "\n",
    "#### Logging framework level events\n",
    "To log framework level events for debugging and benchmarking, the framework standard logger is defined and used: `logger = get_logger(__name__)`. To log these, use `logger.log(<log entry>)`. Everything logged this way is appended to `clembench.log`.\n",
    "### Episode setup\n",
    "The `_on_setup()` method gets all keys=values in the instance dictionary, as we defined above. Use this method to set up everything that is needed so that the game can be played.\n",
    "\n",
    "We want to access certain game instance values easily, like the number of turns need to successfully finish a game of `firstlast`. In the template `_on_setup()` method definition, assign the game instance value to `self.n_turns`: `self.n_turns = game_instance['n_turns']`\n",
    "\n",
    "We then instantiate both players (including adding the initial prompts to their message history):\n",
    "Replace\n",
    "```python\n",
    "self.some_player = SomeGamePlayer(self.player_models[0])\n",
    "# with\n",
    "self.player_a = Speaker(self.player_models[0], 'A', game_instance['first_letter'])\n",
    "self.player_b = Speaker(self.player_models[1], 'B', game_instance['first_letter'])\n",
    "```\n",
    "\n",
    "The two players need to be added to allow iteration. We also pass them their respective initial prompts here:\n",
    "Replace\n",
    "```python\n",
    "self.add_player(self.some_player, initial_context=game_instance['initial_prompt'])\n",
    "# with\n",
    "self.add_player(self.player_a, initial_context=game_instance['prompt_player_a'])\n",
    "self.add_player(self.player_b, initial_prompt=game_instance['prompt_player_b'])\n",
    "```\n",
    "Note that the first player assignment uses the argument `initial_context`, while the second one uses `initial_prompt` - this is required at player assignment to properly establish the first player's context, otherwise its message history would be incomplete.\n",
    "\n",
    "Next we assign the `current_turn` attribute, to keep track of the number of turns. (The `DialogueGameMaster` parent class already has the attribute `current_round`, but we want to track individual turns for `firstlast`.) We assign the first letter to the attribute `current_letter` and log it to be accessible for scoring later:\n",
    "```python\n",
    "# initialise game variables:\n",
    "self.current_turn: int = 0\n",
    "self.current_letter: str = game_instance['first_letter']\n",
    "# log additional key that will be relevant for evaluation:\n",
    "self.log_key('n_turns', game_instance['n_turns'])\n",
    "```\n",
    "\n",
    "To keep track of correctness of the latest response (`correct_response`), turn-level success scores (`turn_scores`) and the number of correctly completed turns (`complete_turns`), we assign corresponding attributes:\n",
    "```python\n",
    "self.correct_response = False\n",
    "self.turn_scores = [0] * (self.n_turns)\n",
    "self.complete_turns: int = 0\n",
    "```\n",
    "\n",
    "Lastly, we assign attributes to keep track of (in)valid requests (`request_count, parsed_request_count, violated_request_count`) and if the game was aborted or lost:\n",
    "```python\n",
    "# initialise common metrics:\n",
    "self.request_count: int = 0\n",
    "self.parsed_request_count: int = 0\n",
    "self.violated_request_count: int = 0\n",
    "\n",
    "# initialise attributes that will be used for the evaluation scores\n",
    "self.aborted: bool = False\n",
    "self.lose: bool = False\n",
    "```\n",
    "**IMPORTANT:** These values are mandatory clemcore scores and MUST be implemented and recorded!\n",
    "\n",
    "The `FirstLast` `_on_setup()` method should now look like this:\n",
    "```python\n",
    "    def _on_setup(self, **game_instance) -> None:\n",
    "        \"\"\"\n",
    "        Set up the episode (mandatory).\n",
    "        Args:\n",
    "            game_instance: The game instance dict.\n",
    "        \"\"\"\n",
    "        self.game_instance: dict = game_instance\n",
    "\n",
    "        self.n_turns: int = game_instance['n_turns']\n",
    "\n",
    "        # instantiate both players:\n",
    "        self.player_a = Speaker(self.player_models[0], 'A', game_instance['first_letter'])\n",
    "        self.player_b = Speaker(self.player_models[1], 'B', game_instance['first_letter'])\n",
    "\n",
    "        # add players, including assigning their initial prompts:\n",
    "        self.add_player(self.player_a, initial_context=game_instance['prompt_player_a'])\n",
    "        self.add_player(self.player_b, initial_prompt=game_instance['prompt_player_b'])\n",
    "\n",
    "        # initialise game variables:\n",
    "        self.current_turn: int = 0\n",
    "        self.current_letter: str = game_instance['first_letter']\n",
    "        # log any additional keys that will be relevant for evaluation\n",
    "        self.log_key('n_turns', game_instance['n_turns'])\n",
    "\n",
    "        self.correct_response = False\n",
    "        self.turn_scores = [0] * (self.n_turns)\n",
    "        self.complete_turns: int = 0\n",
    "\n",
    "        # initialise common metrics:\n",
    "        self.request_count: int = 0\n",
    "        self.parsed_request_count: int = 0\n",
    "        self.violated_request_count: int = 0\n",
    "\n",
    "        # initialise attributes that will be used for the evaluation scores\n",
    "        self.aborted: bool = False\n",
    "        self.lose: bool = False\n",
    "```\n",
    "Summary:\n",
    "- The setup must define players and log other game-specific keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45105f91b7acf8bf",
   "metadata": {},
   "source": [
    "### Playing the game\n",
    "The `DialogueGameMaster` base class comes with a play loop already implemented. It has a number of hook methods that are called inside of this play loop, and game specifics are to be implemented within these methods.\n",
    "\n",
    "This is the `play()` method of `DialogueGameMaster`:\n",
    "```python\n",
    "    def play(self) -> None:\n",
    "        \"\"\"Main play loop method.\n",
    "        This method is called to run the game for benchmarking.\n",
    "        \"\"\"\n",
    "        done = False\n",
    "        while not done:\n",
    "            # get the current context message for the current player, set by set_context_for():\n",
    "            context = self.get_context_for(self.current_player)\n",
    "            # generate/get response from the player based on their message history and the passed context message:\n",
    "            response = self.current_player(context)\n",
    "            # pass the player response to the step() method for processing and determining if play continues:\n",
    "            done, _ = self.process_turn(response)\n",
    "```\n",
    "The `process_turn()` method makes method calls in this sequence:\n",
    "1. **\\_parse_response(self.current_player, response)**: Decide if a response follows the move format rule, should be modified and apply modifications.\n",
    "2. **\\_advance_game(self.current_player, parsed_response)**: Method executed after a player response has been parsed. Checks for game rule adherence and advances the game state.\n",
    "3. **\\_on_parse_error()**: Method executed if the response could not be parsed, usually due to not following the move format rule.\n",
    "4. **\\_on_game_error()**: Method executed if the response is not following further game rules.\n",
    "5. **compute_turn_score(response, context)**: Calculate a turn-level score for this player response.\n",
    "6. get_turn_feedback(response, context): Create textual feedback to the player response.\n",
    "7. _should_pass_turn(): Determine if a player is done for the current round.\n",
    "8. _next_player(): The game master passes the turn to the next player in the player list (order as added).\n",
    "9. _start_next_round(): Start next round when we cycled through the whole list i.e. it is again the first player's turn.\n",
    "10. **\\_does_game_proceed()**: Check if game should proceed.\n",
    "11. _on_before_round(): Executed in the play loop before a new round of gameplay starts.\n",
    "12. _on_after_round(): Executed in the play loop after a round of gameplay finishes i.e. _start_next_round() resolves to True.\n",
    "13. **_on_after_game()**: Executed once at the end, after exiting the play loop.\n",
    "\n",
    "While all listed methods can be adapted for your game, we will implement adapted versions of the bolded methods. Implementation of the methods `_on_setup()`, `compute_turn_score()`, `compute_episode_score()`, `_advance_game()` and `_does_game_proceed()` is mandatory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e358251cb8bd758",
   "metadata": {},
   "source": [
    "#### _parse_response()\n",
    "The `_parse_response()` method checks for move format rule adherence and processes the response further. Since every response comes from a backend request, we increment `request_count`. We also add the response of the current player as the context message for the next player's round. For `firstlast`, we have a single move format rule: Player responses must start with `I SAY: `. If this rule is not followed `ParseError` is raised and the episode is aborted ([here](#_on_parse_error())). If the rule was followed, we log an event for transcripts and return the first and last word of the response (removing `I SAY:`). Replace the template method with the following:\n",
    "```python\n",
    "    def _parse_response(self, player: Player, response: str) -> Tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Add the response to the other player's message history and check if the response follows the move format rule,\n",
    "        then split the response and return the first and last word.\n",
    "        Args:\n",
    "            player: The player that produced the response.\n",
    "            response: The response string.\n",
    "        Returns:\n",
    "            Tuple of the first and last word of the response.\n",
    "        Raises:\n",
    "            ParseError: If the response is missing 'I SAY: '.\n",
    "        \"\"\"\n",
    "        # increase the number of API requests:\n",
    "        self.request_count += 1\n",
    "\n",
    "        if player == self.player_a:\n",
    "            self.set_context_for(self.player_b, response)\n",
    "        if player == self.player_b:\n",
    "            self.set_context_for(self.player_a, response)\n",
    "\n",
    "        # check for move format tag:\n",
    "        if not response.startswith(\"I SAY: \"):\n",
    "            raise ParseError()\n",
    "\n",
    "        # increase the counter of requests that conform to form rules\n",
    "        self.parsed_request_count += 1\n",
    "        # log the event that the string was valid (no strange characters)\n",
    "        action = {'type': 'metadata', 'content': 'move format followed'}\n",
    "        self.log_event(from_='GM', to='GM', action=action)\n",
    "\n",
    "        # remove the move format tag and split on whitespace:\n",
    "        words = response[7:].split()\n",
    "        return words[0].lower(), words[-1].lower()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f69a0891b1f9ba",
   "metadata": {},
   "source": [
    "#### _on_parse_error()\n",
    "This method aborts the game if the move format rule was not followed. It is called if a `ParseError` is raised during the execution of `_parse_response()` and `_advance_game()`. We also increment the `violated_request_count` and log that the response didn't follow the required format for transcripts. Replace the template method definition with the following:\n",
    "```python\n",
    "    def _on_parse_error(self, error: GameError):\n",
    "        \"\"\"Abort the game due to failed parsing.\"\"\"\n",
    "        # set the game to be aborted:\n",
    "        self.aborted = True\n",
    "        # increase the counter of requests that violate the move format rule:\n",
    "        self.violated_request_count += 1\n",
    "        # log the abortion event:\n",
    "        action = {'type': 'missing tag', 'content': 'abort'}\n",
    "        self.log_event(from_='GM', to='GM', action=action)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66118dadf6014bc6",
   "metadata": {},
   "source": [
    "#### _advance_game()\n",
    "The `_advance_game()` checks if the player's response conforms to the game's other rules. If the letter rule isn't followed, the episode is lost. If the rules are followed, we log an event for trsnacripts and set this turn's score to 1. Then the method advances the game state if the response follows the rules, setting relevant attributes. We increment `current_turn` and set the next letter in the alphabet to be the new `current_letter`. Replace the template method definition with the following:\n",
    "```python\n",
    "    def _advance_game(self, player: Player, parsed_response: Tuple[str, str]):\n",
    "        \"\"\"\n",
    "        Check if the parsed response follows the game rules. Then advance the game state, preparing the next player's turn.\n",
    "        Args:\n",
    "            player: The current player.\n",
    "            parsed_response: The parsed response, a tuple of the first and last word of the response.\n",
    "        \"\"\"\n",
    "        first_word_correct_letter = parsed_response[0][0] == self.current_letter  # True if the first letter of the first word in the response is correct\n",
    "        last_word_correct_letter = parsed_response[0][0] == parsed_response[1][0]  # True if the first letters of the first and last word match\n",
    "        self.correct_response = first_word_correct_letter and last_word_correct_letter\n",
    "        if not self.correct_response:\n",
    "            raise RuleViolationError(f'{parsed_response[0]}/{parsed_response[1]} violates rules')  # RuleViolationError inherits from GameError\n",
    "        else:\n",
    "            # log the fact that the answer was correct:\n",
    "            action = {'type': 'valid response',\n",
    "                      'content': f'{parsed_response[0]}/{parsed_response[1]} conforms to rules'}\n",
    "            self.log_event(from_='GM', to='GM', action=action)\n",
    "            # set the current turn's score to 1:\n",
    "            self.turn_scores[self.current_turn - 1] = 1\n",
    "        # increment current turn:\n",
    "        self.current_turn += 1\n",
    "        # increment complete turns:\n",
    "        self.complete_turns += 1\n",
    "        # update the letter being played:\n",
    "        current_index = letters.index(self.current_letter)\n",
    "        self.current_letter = letters[current_index + 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ec594124825e5",
   "metadata": {},
   "source": [
    "#### _on_game_error()\n",
    "This method declares the game lost if the game rules were not followed. It is called if a `GameError` is raised during the execution of `_parse_response()` and `_advance_game()`. We also log that the response didn't follow the rules for transcripts. Replace the template method definition with the following:\n",
    "```python\n",
    "    def _on_game_error(self, error: GameError):\n",
    "        \"\"\"Lose the game due to violated rules.\"\"\"\n",
    "        self.lose = True\n",
    "        # log the fact that the game is now lost:\n",
    "        action = {'type': 'rule violation',\n",
    "                  'content': error.reason}\n",
    "        self.log_event(from_='GM', to='GM', action=action)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17455c5051b07733",
   "metadata": {},
   "source": [
    "#### compute_turn_score()\n",
    "This method assigns a score for the response for the playpen reinforcement learning part of clemcore. We simply use the prior turn score for this (since we already incremented the turn in `_advance_game()`). Replace the template method definition with the following:\n",
    "```python\n",
    "    def compute_turn_score(self):\n",
    "        \"\"\"\n",
    "        Compute a score the last player context.\n",
    "        Args:\n",
    "            response: The player response string to be scored.\n",
    "            context: The context message that was added to the player message history to produce the response.\n",
    "        Returns:\n",
    "            1 if the firstlast game rules were followed, 0 otherwise.\n",
    "        \"\"\"\n",
    "        return self.turn_scores[self.current_turn-1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7ea36c0755c2ae",
   "metadata": {},
   "source": [
    "#### _does_game_proceed()\n",
    "The `_does_game_proceed()` method determines if the episode should continue. Episodes are ended if:\n",
    "- The required number of rounds has been reached, making the episode successful.\n",
    "- The move format rule was violated, aborting the episode.\n",
    "- The letter rule was violated, losing the episode.\n",
    "Replace the template method definition with the following:\n",
    "```python\n",
    "    def _does_game_proceed(self) -> bool:\n",
    "        \"\"\"Check if game should proceed.\"\"\"\n",
    "        return (self.current_turn < self.n_turns\n",
    "                and not self.aborted\n",
    "                and not self.lose)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d295beb67ad9150e",
   "metadata": {},
   "source": [
    "#### compute_episode_score()\n",
    "This method calculates an overall score for the episode. We sum up the turn scores, divide them by the target number of turns and multiply this by 100 (to fit the required 0-100 score range). Replace the template method definition with the following:\n",
    "```python\n",
    "    def compute_episode_score(self):\n",
    "        \"\"\"\n",
    "        Calculate a score for the episode based on successful turns and target number of turns.\n",
    "        Returns:\n",
    "            Episode score value in range 0-100.\n",
    "        \"\"\"\n",
    "        turn_score_sum = sum(self.turn_scores)\n",
    "        success_ratio = turn_score_sum / self.n_turns\n",
    "        return success_ratio * 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6205620caad80844",
   "metadata": {},
   "source": [
    "#### _on_after_game()\n",
    "Finally, we record counts and values that are used later for scoring with the `_on_after_game()` method. Replace the template method definition with the following:\n",
    "\n",
    "```python\n",
    "    def _on_after_game(self) -> None:\n",
    "        \"\"\"Log variables needed for scoring.\"\"\"\n",
    "        # log a message informing that the game was successfully played:\n",
    "        if not self.aborted and not self.lose:\n",
    "            action = {'type': 'info', 'content': 'game successful'}\n",
    "            self.log_event(from_='GM', to='GM', action=action)\n",
    "        # log a final message saying that the game did come to an end:\n",
    "        action = {'type': 'info', 'content': 'end game'}\n",
    "        self.log_event(from_='GM', to='GM', action=action)\n",
    "        # log firstlast-specific values:\n",
    "        self.log_key('Played turns', self.current_turn)\n",
    "        self.log_key('Complete turns', self.complete_turns)\n",
    "        self.log_key('Turn scores', self.turn_scores)\n",
    "        # log standard metrics:\n",
    "        self.log_key(ms.METRIC_ABORTED, self.aborted)\n",
    "        self.log_key(ms.METRIC_LOSE, self.lose)\n",
    "        self.log_key(ms.METRIC_REQUEST_COUNT, self.request_count)\n",
    "        self.log_key(ms.METRIC_REQUEST_COUNT_PARSED, self.parsed_request_count)\n",
    "        self.log_key(ms.METRIC_REQUEST_COUNT_VIOLATED, self.violated_request_count)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f55c08c0c49f7",
   "metadata": {},
   "source": [
    "### Full example game master\n",
    "The cell below shows the combined code for the firstlast game master."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11871d116ccf37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from typing import Dict, Tuple, List, Union\n",
    "from string import ascii_lowercase as letters\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import clemcore.metrics as ms\n",
    "from clemcore.clemgame import GameSpec, GameMaster, GameBenchmark, Player, DialogueGameMaster, GameScorer, \\\n",
    "    GameError, ParseError, RuleViolationError\n",
    "from clemcore.backends import Model\n",
    "\n",
    "# import the Speaker player class:\n",
    "from player import Speaker\n",
    "\n",
    "# initialize logging:\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class FirstLast(DialogueGameMaster):\n",
    "    \"\"\"Implement mechanisms for playing FirstLast.\"\"\"\n",
    "    def __init__(self, game_name: str, game_path: str, experiment: Dict, player_models: List[Model]):\n",
    "        super().__init__(game_name, game_path, experiment, player_models)\n",
    "\n",
    "    def _on_setup(self, **game_instance) -> None:\n",
    "        \"\"\"\n",
    "        Set up the episode (mandatory).\n",
    "        Args:\n",
    "            game_instance: The game instance dict.\n",
    "        \"\"\"\n",
    "        self.game_instance: dict = game_instance\n",
    "\n",
    "        self.n_turns: int = game_instance['n_turns']\n",
    "\n",
    "        # instantiate both players:\n",
    "        self.player_a = Speaker(self.player_models[0], 'A', game_instance['first_letter'])\n",
    "        self.player_b = Speaker(self.player_models[1], 'B', game_instance['first_letter'])\n",
    "\n",
    "        # add players, including assigning their initial prompts:\n",
    "        self.add_player(self.player_a, initial_context=game_instance['prompt_player_a'])\n",
    "        self.add_player(self.player_b, initial_prompt=game_instance['prompt_player_b'])\n",
    "\n",
    "        # initialise game variables:\n",
    "        self.current_turn: int = 0\n",
    "        self.current_letter: str = game_instance['first_letter']\n",
    "        # log any additional keys that will be relevant for evaluation\n",
    "        self.log_key('n_turns', game_instance['n_turns'])\n",
    "\n",
    "        self.correct_response = False\n",
    "        self.turn_scores = [0] * (self.n_turns)\n",
    "        self.complete_turns: int = 0\n",
    "\n",
    "        # initialise common metrics:\n",
    "        self.request_count: int = 0\n",
    "        self.parsed_request_count: int = 0\n",
    "        self.violated_request_count: int = 0\n",
    "\n",
    "        # initialise attributes that will be used for the evaluation scores\n",
    "        self.aborted: bool = False\n",
    "        self.lose: bool = False\n",
    "\n",
    "    def _parse_response(self, player: Player, response: str) -> Tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Add the response to the other player's message history and check if the response follows the move format rule,\n",
    "        then split the response and return the first and last word.\n",
    "        Args:\n",
    "            player: The player that produced the response.\n",
    "            response: The response string.\n",
    "        Returns:\n",
    "            Tuple of the first and last word of the response.\n",
    "        Raises:\n",
    "            ParseError: If the response is missing 'I SAY: '.\n",
    "        \"\"\"\n",
    "        # increase the number of API requests:\n",
    "        self.request_count += 1\n",
    "\n",
    "        if player == self.player_a:\n",
    "            self.set_context_for(self.player_b, response)\n",
    "        if player == self.player_b:\n",
    "            self.set_context_for(self.player_a, response)\n",
    "\n",
    "        # check for move format tag:\n",
    "        if not response.startswith(\"I SAY: \"):\n",
    "            raise ParseError()\n",
    "\n",
    "        # increase the counter of requests that conform to form rules\n",
    "        self.parsed_request_count += 1\n",
    "        # log the event that the string was valid (no strange characters)\n",
    "        action = {'type': 'metadata', 'content': 'move format followed'}\n",
    "        self.log_event(from_='GM', to='GM', action=action)\n",
    "\n",
    "        # remove the move format tag and split on whitespace:\n",
    "        words = response[7:].split()\n",
    "        return words[0].lower(), words[-1].lower()\n",
    "\n",
    "    def _on_parse_error(self, error: GameError):\n",
    "        \"\"\"Abort the game due to failed parsing.\"\"\"\n",
    "        # set the game to be aborted:\n",
    "        self.aborted = True\n",
    "        # increase the counter of requests that violate the move format rule:\n",
    "        self.violated_request_count += 1\n",
    "        # log the abortion event:\n",
    "        action = {'type': 'missing tag', 'content': 'abort'}\n",
    "        self.log_event(from_='GM', to='GM', action=action)\n",
    "\n",
    "    def _advance_game(self, player: Player, parsed_response: Tuple[str, str]):\n",
    "        \"\"\"\n",
    "        Check if the parsed response follows the game rules. Then advance the game state, preparing the next player's turn.\n",
    "        Args:\n",
    "            player: The current player.\n",
    "            parsed_response: The parsed response, a tuple of the first and last word of the response.\n",
    "        \"\"\"\n",
    "        first_word_correct_letter = parsed_response[0][0] == self.current_letter  # True if the first letter of the first word in the response is correct\n",
    "        last_word_correct_letter = parsed_response[0][0] == parsed_response[1][0]  # True if the first letters of the first and last word match\n",
    "        self.correct_response = first_word_correct_letter and last_word_correct_letter\n",
    "        if not self.correct_response:\n",
    "            raise RuleViolationError(f'{parsed_response[0]}/{parsed_response[1]} violates rules')  # RuleViolationError inherits from GameError\n",
    "        else:\n",
    "            # log the fact that the answer was correct:\n",
    "            action = {'type': 'valid response',\n",
    "                      'content': f'{parsed_response[0]}/{parsed_response[1]} conforms to rules'}\n",
    "            self.log_event(from_='GM', to='GM', action=action)\n",
    "            # set the current turn's score to 1:\n",
    "            self.turn_scores[self.current_turn - 1] = 1\n",
    "        # increment current turn:\n",
    "        self.current_turn += 1\n",
    "        # increment complete turns:\n",
    "        self.complete_turns += 1\n",
    "        # update the letter being played:\n",
    "        current_index = letters.index(self.current_letter)\n",
    "        self.current_letter = letters[current_index + 1]\n",
    "\n",
    "    def _on_game_error(self, error: GameError):\n",
    "        \"\"\"Lose the game due to violated rules.\"\"\"\n",
    "        self.lose = True\n",
    "        # log the fact that the game is now lost:\n",
    "        action = {'type': 'rule violation',\n",
    "                  'content': error.reason}\n",
    "        self.log_event(from_='GM', to='GM', action=action)\n",
    "\n",
    "    def compute_turn_score(self):\n",
    "        \"\"\"\n",
    "        Compute a score the last player context.\n",
    "        Args:\n",
    "            response: The player response string to be scored.\n",
    "            context: The context message that was added to the player message history to produce the response.\n",
    "        Returns:\n",
    "            1 if the firstlast game rules were followed, 0 otherwise.\n",
    "        \"\"\"\n",
    "        return self.turn_scores[self.current_turn-1]\n",
    "\n",
    "    def _does_game_proceed(self) -> bool:\n",
    "        \"\"\"Check if game should proceed.\"\"\"\n",
    "        return (self.current_turn < self.n_turns\n",
    "                and not self.aborted\n",
    "                and not self.lose)\n",
    "\n",
    "    def compute_episode_score(self):\n",
    "        \"\"\"\n",
    "        Calculate a score for the episode based on successful turns and target number of turns.\n",
    "        Returns:\n",
    "            Episode score value in range 0-100.\n",
    "        \"\"\"\n",
    "        turn_score_sum = sum(self.turn_scores)\n",
    "        success_ratio = turn_score_sum / self.n_turns\n",
    "        return success_ratio * 100\n",
    "\n",
    "    def _on_after_game(self) -> None:\n",
    "        \"\"\"Log variables needed for scoring.\"\"\"\n",
    "        # log a message informing that the game was successfully played:\n",
    "        if not self.aborted and not self.lose:\n",
    "            action = {'type': 'info', 'content': 'game successful'}\n",
    "            self.log_event(from_='GM', to='GM', action=action)\n",
    "        # log a final message saying that the game did come to an end:\n",
    "        action = {'type': 'info', 'content': 'end game'}\n",
    "        self.log_event(from_='GM', to='GM', action=action)\n",
    "        # log firstlast-specific values:\n",
    "        self.log_key('Played turns', self.current_turn)\n",
    "        self.log_key('Complete turns', self.complete_turns)\n",
    "        self.log_key('Turn scores', self.turn_scores)\n",
    "        # log standard metrics:\n",
    "        self.log_key(ms.METRIC_ABORTED, self.aborted)\n",
    "        self.log_key(ms.METRIC_LOSE, self.lose)\n",
    "        self.log_key(ms.METRIC_REQUEST_COUNT, self.request_count)\n",
    "        self.log_key(ms.METRIC_REQUEST_COUNT_PARSED, self.parsed_request_count)\n",
    "        self.log_key(ms.METRIC_REQUEST_COUNT_VIOLATED, self.violated_request_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b331dbd2a6013d61",
   "metadata": {},
   "source": [
    "# GameScorer implementation\n",
    "Each clemgame needs a game scorer, a child class of the clemcore `GameScorer` base class. The game scorer reads episode records and calculates evaluation scores. The `GameScorer` base class handles standard scores by default, so we only need to complete two methods: `score_turns()` to calculate and log turn-level scores, and `log_main_score()` to calculate and log the episode's benchmark score. Replace the template definition with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8686ab2f61ceb83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstLastScorer(GameScorer):\n",
    "    \"\"\"Scorer for the firstlast game.\"\"\"\n",
    "    def __init__(self, game_name: str, experiment: Dict, game_instance: Dict):\n",
    "        super().__init__(game_name, experiment, game_instance)\n",
    "\n",
    "    def score_turns(self, episode_interactions: Dict) -> None:\n",
    "        \"\"\"Calculate and log turn-level scores.\"\"\"\n",
    "        played_turns = episode_interactions['Played turns']\n",
    "        turn_scores = episode_interactions['Turn scores']\n",
    "        for turn in range(0, played_turns):\n",
    "            self.log_round_score(turn, \"turn score\", turn_scores[turn])\n",
    "\n",
    "    def log_main_score(self, episode_interactions: Dict):\n",
    "        complete_turns = episode_interactions['Complete turns']\n",
    "        n_turns = episode_interactions['n_turns']\n",
    "        aborted = int(episode_interactions[ms.METRIC_ABORTED])\n",
    "        # IMPORTANT: aborted episodes MUST have a bench score of NaN!\n",
    "        bench_score = complete_turns / n_turns if not aborted else np.nan\n",
    "        self.log_episode_score(ms.BENCH_SCORE, bench_score)\n",
    "\n",
    "    def compute_scores(self, episode_interactions: Dict) -> None:\n",
    "        # Log turn-level scores\n",
    "        self.score_turns(episode_interactions)\n",
    "        # Log main score\n",
    "        self.log_main_score(episode_interactions)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b1bb50fe515441",
   "metadata": {},
   "source": [
    "# Game registry\n",
    "Every clemgame needs a game registry entry, stored as `clemgame.json` in the game's root directory. It is required for the clemcore framework to find the game and its file system path.\n",
    "\n",
    "The contents for firstlast are:\n",
    "```json\n",
    "{\n",
    "  \"game_name\": \"firstlast\",\n",
    "  \"description\": \"Firstlast game between two players that must match the first letters of the first and last word of their responses.\",\n",
    "  \"main_game\": \"firstlast\",\n",
    "  \"players\": \"two\",\n",
    "  \"image\": \"none\",\n",
    "  \"languages\": [\"en\"],\n",
    "  \"benchmark\": []\n",
    "}\n",
    "```\n",
    "Create a JSON file in the `firstlast` directory and copy the game registry entry into it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cca10af0d25e23",
   "metadata": {},
   "source": [
    "# GameBenchmark implementation\n",
    "\n",
    "We need to define which classes the `clemcore` framework needs to run our game. This can be done in the same file where the GameMaster lives. We need to create a child of `GameBenchmark`. We also add a short description of the game and the method that calls the FirstLast game master.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20abaab7043e7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put this at the end of firstlast/master.py\n",
    "\n",
    "# always add the GameBenchmark child with this structure\n",
    "class FirstLastGameBenchmark(GameBenchmark):\n",
    "    \"\"\"Integrate the game into the benchmark run.\"\"\"\n",
    "    def __init__(self, game_spec: GameSpec):\n",
    "        super().__init__(game_spec)\n",
    "\n",
    "    def create_game_master(self,\n",
    "                           experiment: Dict,\n",
    "                           player_models: List[Model]\n",
    "                           ) -> GameMaster:\n",
    "        return FirstLast(self.game_name, self.game_path, experiment, player_models)\n",
    "\n",
    "    def create_game_scorer(self, experiment: Dict, game_instance: Dict) -> GameScorer:\n",
    "        return FirstLastScorer(self.game_name, experiment, game_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6106d4e764faaa05",
   "metadata": {},
   "source": [
    "With this done, the example `firstlast` clemgame is ready to run - but we should test it, and it is very likely that you need to refine your clemgame. The next section has suggestions how to go about this.\n",
    "# Testing and refinement\n",
    "## Running your clemgame\n",
    "To run the example `firstlast` clemgame, make sure that you have activated the virtual environment that has `clemcore` installed. We will use a model named `gemma-3-27b-it-UP` here, which is accessing a remote API. Enter the following into your terminal:\n",
    "```\n",
    "(clemcore_venv) clem run -g firstlast -m gemma-3-27b-it-UP\n",
    "```\n",
    "This will run the game with the instances we created earlier, create `interactions.json` and `requests.json` record files in the `results/firstlast` directory in subdirectories for each experiment and episode, and then score episodes based on the records, producing a `scores.json` file for each episode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7579549658d3fb03",
   "metadata": {},
   "source": [
    "## Checking game records\n",
    "The most important record file of each episode to check is `interactions.json`, as it is supposed to contain all relevant information to score and transcribe the episode.\n",
    "\n",
    "The `interactions.json` file in the `results/firstlast/0_dogs/episode_0` directory should have the following content:\n",
    "```json\n",
    "{\n",
    "  \"meta\": {\n",
    "    \"experiment_name\": \"dogs\",\n",
    "    \"game_id\": 0,\n",
    "    \"dialogue_pair\": \"gemma-3-27b-it-UP-t0.0--gemma-3-27b-it-UP-t0.0\"\n",
    "  },\n",
    "  \"players\": {\n",
    "    \"GM\": \"Game master for firstlast\",\n",
    "    \"Player 1 (Speaker)\": \"Player 1 (Speaker) (Speaker): gemma-3-27b-it-UP\",\n",
    "    \"Player 2 (Speaker)\": \"Player 2 (Speaker) (Speaker): gemma-3-27b-it-UP\"\n",
    "  },\n",
    "  \"turns\": [\n",
    "    [\n",
    "      {\n",
    "        \"from\": \"GM\",\n",
    "        \"to\": \"Player 1 (Speaker)\",\n",
    "        \"timestamp\": \"2025-04-16T18:57:53.881302\",\n",
    "        \"action\": {\n",
    "          \"type\": \"send message\",\n",
    "          \"content\": \"Let's play a game. You must have a conversation about dogs with your partner. Your first turn must start and end with words that begin with the letter a. The reply of your partner must be similar, with the letter that comes after a in the alphabet. Then it's your turn again with the next letter, and so on. You'll do it for 5 turns. Always start your utterance with I SAY: and then give your answer. If you break the rules, you lose.\",\n",
    "          \"label\": \"context\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"from\": \"Player 1 (Speaker)\",\n",
    "        \"to\": \"GM\",\n",
    "        \"timestamp\": \"2025-04-16T18:57:55.901125\",\n",
    "        \"action\": {\n",
    "          \"type\": \"get message\",\n",
    "          \"content\": \"Okay, I understand the rules! Let's begin.\\n\\n**I SAY:** Absolutely adorable animals are dogs, aren't they? A fluffy golden retriever is my dream!\\n\\n\\n\\n**(Waiting for partner's \\\"B\\\" response)**\",\n",
    "          \"label\": \"response\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"from\": \"GM\",\n",
    "        \"to\": \"GM\",\n",
    "        \"timestamp\": \"2025-04-16T18:57:55.901125\",\n",
    "        \"action\": {\n",
    "          \"type\": \"invalid format\",\n",
    "          \"content\": \"abort\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"from\": \"GM\",\n",
    "        \"to\": \"GM\",\n",
    "        \"timestamp\": \"2025-04-16T18:57:55.901125\",\n",
    "        \"action\": {\n",
    "          \"type\": \"info\",\n",
    "          \"content\": \"end game\"\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  ],\n",
    "  \"n_turns\": 5,\n",
    "  \"Played turns\": 1,\n",
    "  \"Complete turns\": 0,\n",
    "  \"Turn scores\": [\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0\n",
    "  ],\n",
    "  \"Aborted\": true,\n",
    "  \"Lose\": false,\n",
    "  \"Request Count\": 1,\n",
    "  \"Parsed Request Count\": 0,\n",
    "  \"Violated Request Count\": 1\n",
    "}\n",
    "```\n",
    "The `scores.json` file in the `results/firstlast/0_dogs/episode_0` directory should have the following content:\n",
    "```json\n",
    "{\n",
    "  \"turn scores\": {\n",
    "    \"0\": {\n",
    "      \"turn score\": 1\n",
    "    }\n",
    "  },\n",
    "  \"episode scores\": {\n",
    "    \"Aborted\": 1,\n",
    "    \"Lose\": 0,\n",
    "    \"Success\": 0,\n",
    "    \"Request Count\": 1,\n",
    "    \"Parsed Request Count\": 0,\n",
    "    \"Violated Request Count\": 1,\n",
    "    \"Request Success Ratio\": 0.0,\n",
    "    \"Main Score\": NaN\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3910276065d15f6b",
   "metadata": {},
   "source": [
    "As we can see, the episode was aborted (`\"episode scores\": {\"Aborted\": 1,...}` in `scores.json`) due to a violated request (`\"Violated Request Count\": 1`).\n",
    "\n",
    "Checking `interactions.json`, we can see the episode was aborted in the first turn, due to Player 1's response having invalid format:\n",
    "```json\n",
    "      {\n",
    "        \"from\": \"GM\",\n",
    "        \"to\": \"GM\",\n",
    "        \"timestamp\": \"2025-04-16T18:57:55.901125\",\n",
    "        \"action\": {\n",
    "          \"type\": \"invalid format\",\n",
    "          \"content\": \"abort\"\n",
    "        }\n",
    "      }\n",
    "```\n",
    "The `get message` event recorded right above contains the response text that led to this:\n",
    "```json\n",
    "      {\n",
    "        \"from\": \"Player 1 (Speaker)\",\n",
    "        \"to\": \"GM\",\n",
    "        \"timestamp\": \"2025-04-16T18:57:55.901125\",\n",
    "        \"action\": {\n",
    "          \"type\": \"get message\",\n",
    "          \"content\": \"Okay, I understand the rules! Let's begin.\\n\\n**I SAY:** Absolutely adorable animals are dogs, aren't they? A fluffy golden retriever is my dream!\\n\\n\\n\\n**(Waiting for partner's \\\"B\\\" response)**\",\n",
    "          \"label\": \"response\"\n",
    "        }\n",
    "      }\n",
    "```\n",
    "The response content is `Okay, I understand the rules! Let's begin.\\n\\n**I SAY:** Absolutely adorable animals are dogs, aren't they? A fluffy golden retriever is my dream!\\n\\n\\n\\n**(Waiting for partner's \\\"B\\\" response)**` - the model fails to follow the move format rule by producing an acknowledgment of the rules stated in the initial prompt, leading to the abort. (It also does not follow the first letter rule for the last word of its proper reply, but we'll only address the first issue to keep this example short. Fully refining prompts and processing by the game master can be an extended process.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ea2e1ac51372c",
   "metadata": {},
   "source": [
    "## Refinement: Initial prompt engineering\n",
    "Based on the move format violation issue above, we'll adjust the initial prompts, adding the instruction `Do not state that you understood the rules or add that you are waiting for your partner's response.` to them.\n",
    "\n",
    "Player A:\n",
    "```Let's play a game. You must have a conversation about $topic with your partner. Your first turn must start and end with words that begin with the letter $letter. The reply of your partner must be similar, with the letter that comes after $letter in the alphabet. Then it's your turn again with the next letter, and so on. You'll do it for $n_turns turns. Always start your utterance with I SAY: and then give your answer. Do not state that you understood the rules or add that you are waiting for your partner's response. If you break the rules, you lose.```\n",
    "\n",
    "Player B:\n",
    "```Let's play a game. You must have a conversation about $topic with your partner. Their first turn must start and end with words that begin with the letter $letter. Your reply must be similar, with the letter that comes after $letter in the alphabet. Then it's their turn again with the next letter, and so on. You'll do it for $n_turns turns. Always start your utterance with I SAY: and then give your answer. Do not state that you understood the rules or add that you are waiting for your partner's response. If you break the rules, you lose.```\n",
    "\n",
    "We change this in the `.template` files, then run `instancegenerator.py` to use these new initial prompts in our instance files. (If your game is more complicated and might require more prompt engineering, it can be useful to load the initial prompt templates in your game master and replace template placeholders in its episode setup - that way, you can skip the instance generation step.)\n",
    "\n",
    "**IMPORTANT:** Do not be tempted to optimize your prompting for a single model, as clemgames are intended to be run with a large number of models, each likely handling the prompts differently. Always test with multiple models, and keep your prompting general!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7984bdba8b8f8bc",
   "metadata": {},
   "source": [
    "Then we run the game again like before. The `interactions.json` file in the `results/firstlast/0_dogs/episode_0` directory should now have the following content:\n",
    "```json\n",
    "{\n",
    "  \"meta\": {\n",
    "    \"experiment_name\": \"dogs\",\n",
    "    \"game_id\": 0,\n",
    "    \"dialogue_pair\": \"gemma-3-27b-it-UP-t0.0--gemma-3-27b-it-UP-t0.0\"\n",
    "  },\n",
    "  \"players\": {\n",
    "    \"GM\": \"Game master for firstlast\",\n",
    "    \"Player 1 (Speaker)\": \"Player 1 (Speaker) (Speaker): gemma-3-27b-it-UP\",\n",
    "    \"Player 2 (Speaker)\": \"Player 2 (Speaker) (Speaker): gemma-3-27b-it-UP\"\n",
    "  },\n",
    "  \"turns\": [\n",
    "    [\n",
    "      {\n",
    "        \"from\": \"GM\",\n",
    "        \"to\": \"Player 1 (Speaker)\",\n",
    "        \"timestamp\": \"2025-04-16T20:21:21.125266\",\n",
    "        \"action\": {\n",
    "          \"type\": \"send message\",\n",
    "          \"content\": \"Let's play a game. You must have a conversation about dogs with your partner. Your first turn must start and end with words that begin with the letter a. The reply of your partner must be similar, with the letter that comes after a in the alphabet. Then it's your turn again with the next letter, and so on. You'll do it for 5 turns. Always start your utterance with I SAY: and then give your answer. Do not state that you understood the rules or add that you are waiting for your partner's response. If you break the rules, you lose.\",\n",
    "          \"label\": \"context\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"from\": \"Player 1 (Speaker)\",\n",
    "        \"to\": \"GM\",\n",
    "        \"timestamp\": \"2025-04-16T20:21:21.901309\",\n",
    "        \"action\": {\n",
    "          \"type\": \"get message\",\n",
    "          \"content\": \"I SAY: Absolutely adorable animals are dogs, aren't they?\",\n",
    "          \"label\": \"response\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"from\": \"GM\",\n",
    "        \"to\": \"GM\",\n",
    "        \"timestamp\": \"2025-04-16T20:21:21.901309\",\n",
    "        \"action\": {\n",
    "          \"type\": \"metadata\",\n",
    "          \"content\": \"valid string\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"from\": \"GM\",\n",
    "        \"to\": \"GM\",\n",
    "        \"timestamp\": \"2025-04-16T20:21:21.901309\",\n",
    "        \"action\": {\n",
    "          \"type\": \"parse\",\n",
    "          \"content\": \"absolutely/they? violates rules\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"from\": \"GM\",\n",
    "        \"to\": \"GM\",\n",
    "        \"timestamp\": \"2025-04-16T20:21:21.901309\",\n",
    "        \"action\": {\n",
    "          \"type\": \"info\",\n",
    "          \"content\": \"end game\"\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  ],\n",
    "  \"n_turns\": 5,\n",
    "  \"Played turns\": 1,\n",
    "  \"Complete turns\": 0,\n",
    "  \"Turn scores\": [\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0\n",
    "  ],\n",
    "  \"Aborted\": false,\n",
    "  \"Lose\": true,\n",
    "  \"Request Count\": 1,\n",
    "  \"Parsed Request Count\": 1,\n",
    "  \"Violated Request Count\": 0\n",
    "}\n",
    "```\n",
    "As we can see, the additional instruction worked! The model responded with `I SAY: Absolutely adorable animals are dogs, aren't they?`, without the extraneous acknowledgements of the game procedure. It followed the move format rule as well, correctly starting the response with `I SAY: `. However, the last word it produced is `they?`, which violates the rule that the last word has to start with `a` this turn.\n",
    "\n",
    "The notable difference here is that this episode was not ABORTED, but LOST, as the move format rule *was* followed, but further game rules were not.\n",
    "\n",
    "This wraps up this example clemgame implementation. Your own clemgame will very likely be more complicated, so it is recommended to familiarize yourself deeper with the `clemcore` base classes once you are developing a new clemgame."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
